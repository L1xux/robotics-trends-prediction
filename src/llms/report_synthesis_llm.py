"""
Report Synthesis Agent

Content Analysis AgentÏùò Ï∂úÎ†•(ÏÑπÏÖò 2,3,4,5)ÏùÑ Î∞õÏïÑÏÑú
Summary, Introduction, Conclusion, References, AppendixÎ•º ÏÉùÏÑ±ÌïòÎäî Agent
"""

from typing import List, Any, Dict
from langchain_core.language_models import BaseChatModel
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser

from src.agents.base.base_agent import BaseAgent
from src.agents.base.agent_config import AgentConfig
from src.graph.state import PipelineState
from src.core.models.citation_model import CitationEntry
from config.prompts.synthesis_prompts import SYNTHESIS_PROMPTS


class ReportSynthesisLLM(BaseAgent):
    """
    Report Synthesis Agent
    
    ContentAnalysisAgentÏùò Ï∂úÎ†•ÏùÑ Î∞õÏïÑÏÑú ÎÇòÎ®∏ÏßÄ ÏÑπÏÖòÎì§ÏùÑ ÏÉùÏÑ±:
    - SUMMARY (Executive Summary)
    - Section 1: Introduction
    - Section 6: Conclusion
    - REFERENCE (Citations)
    - APPENDIX (Ï∂îÍ∞Ä ÏûêÎ£å)
    
    Input (from ContentAnalysisAgent):
    - sections: Dict[str, str] (section_2_1, section_2_2, ..., section_5_3)
    - trends: List[TrendTier]
    - citations: List[CitationEntry]
    
    Output:
    - summary: str
    - section_1: str (Introduction)
    - section_6: str (Conclusion)
    - references: str (formatted citations)
    - appendix: str
    """
    
    def __init__(
        self,
        llm: BaseChatModel,
        tools: List[Any],
        config: AgentConfig
    ):
        super().__init__(llm, tools, config)
        self._setup_chains()
    
    def _setup_chains(self):
        """LCEL Chains ÏÑ§Ï†ï"""
        str_parser = StrOutputParser()
        
        # Summary Chain
        summary_prompt = ChatPromptTemplate.from_template(
            """ÎãπÏã†ÏùÄ AI/Î°úÎ≥¥Ìã±Ïä§ Ï†ÑÎ¨∏ Î≥¥Í≥†ÏÑú ÏûëÍ∞ÄÏûÖÎãàÎã§.

Îã§Ïùå Î∂ÑÏÑù Í≤∞Í≥ºÎ•º Î∞îÌÉïÏúºÎ°ú **Executive Summary**Î•º ÏûëÏÑ±ÌïòÏÑ∏Ïöî:

**Í∏∞Ïà† Ìä∏Î†åÎìú Î∂ÑÏÑù (Section 2):**
{section_2}

**ÏãúÏû• ÎèôÌñ• Î∞è ÏÇ∞ÏóÖ Ï†ÅÏö© (Section 3):**
{section_3}

**5ÎÖÑ Í∏∞Ïà† Ï†ÑÎßù (Section 4):**
{section_4}

**ÎπÑÏ¶àÎãàÏä§ ÏãúÏÇ¨Ï†ê (Section 5):**
{section_5}

**ÌïµÏã¨ Ìä∏Î†åÎìú:**
{key_trends}

**Executive Summary ÏûëÏÑ± ÏöîÍµ¨ÏÇ¨Ìï≠:**

1. **Í∏∏Ïù¥**: 200-300Îã®Ïñ¥
2. **Íµ¨Ï°∞**:
   - **ÏöîÏïΩÎ¨∏ (Overview)**: Î≥¥Í≥†ÏÑúÏùò ÌïµÏã¨ ÎÇ¥Ïö©ÏùÑ 2-3Î¨∏Ïû•ÏúºÎ°ú ÏïïÏ∂ï
   - **5ÎÖÑ Ï†ÑÎßù (5-Year Forecast)**: 2025-2030ÎÖÑ Ï£ºÏöî Í∏∞Ïà† Î∞úÏ†Ñ Ï†ÑÎßù (HOT_TRENDSÏôÄ RISING_STARS Ìè¨Ìï®)

3. **ÌÜ§**: Í∞ÑÍ≤∞ÌïòÍ≥† ÏûÑÌå©Ìä∏ ÏûàÍ≤å, Í≤ΩÏòÅÏßÑ ÎåÄÏÉÅ
4. **ÌäπÏßï**: Îç∞Ïù¥ÌÑ∞ Í∏∞Î∞ò, Íµ¨Ï≤¥Ï†Å Ïù∏ÏÇ¨Ïù¥Ìä∏

**Ï£ºÏùò**:
- "Ï£ºÏöî Î∞úÍ≤¨ÏÇ¨Ìï≠", "Í∂åÏû•ÏÇ¨Ìï≠" Îì±ÏùÄ Ìè¨Ìï®ÌïòÏßÄ ÎßàÏÑ∏Ïöî
- ÏöîÏïΩÎ¨∏Í≥º 5ÎÖÑ Ï†ÑÎßùÎßå Ìè¨Ìï®ÌïòÏÑ∏Ïöî
- Í∞Å ÌååÌä∏Îäî Î™ÖÌôïÌûà Íµ¨Î∂ÑÎêòÏñ¥Ïïº Ìï©ÎãàÎã§

Executive SummaryÎßå ÏûëÏÑ±ÌïòÏó¨ Î∞òÌôòÌïòÏÑ∏Ïöî (ÎßàÌÅ¨Îã§Ïö¥ ÌòïÏãù)."""
        )
        self.summary_chain = summary_prompt | self.llm | str_parser
        
        # Introduction Chain
        intro_prompt = ChatPromptTemplate.from_template(
            """ÎãπÏã†ÏùÄ AI/Î°úÎ≥¥Ìã±Ïä§ Ï†ÑÎ¨∏ Î≥¥Í≥†ÏÑú ÏûëÍ∞ÄÏûÖÎãàÎã§.

Î≥¥Í≥†ÏÑú Ï£ºÏ†ú: {topic}

Îã§Ïùå Ï†ïÎ≥¥Î•º Î∞îÌÉïÏúºÎ°ú **1. Introduction**ÏùÑ ÏûëÏÑ±ÌïòÏÑ∏Ïöî:

**ÏàòÏßëÎêú Îç∞Ïù¥ÌÑ∞:**
- ArXiv ÎÖºÎ¨∏: {arxiv_count}Ìé∏
- Ï†ÑÎ¨∏ Î≥¥Í≥†ÏÑú (RAG): {rag_count}Í±¥
- Îâ¥Ïä§ Í∏∞ÏÇ¨: {news_count}Í±¥

**Î≥¥Í≥†ÏÑú Íµ¨Ï°∞:**
- Section 1: Introduction
- Section 2: AI-Robotics Technology Trend Analysis
- Section 3: Market Trends & Applications
- Section 4: 5-Year Forecast (2025-2030)
- Section 5: Implications for Business
- Section 6: Conclusion

**Introduction ÏûëÏÑ± ÏöîÍµ¨ÏÇ¨Ìï≠:**

1. **### Î∞∞Í≤Ω (Background)**:
   - AI/Î°úÎ≥¥Ìã±Ïä§ ÏÇ∞ÏóÖÏùò ÌòÑÌô©Í≥º Ï§ëÏöîÏÑ±
   - Î≥∏ Î≥¥Í≥†ÏÑúÏùò ÌïÑÏöîÏÑ±

2. **### Î™©Ï†Å (Purpose)**:
   - Î≥¥Í≥†ÏÑúÏùò Î™©Ï†ÅÍ≥º Î≤îÏúÑ
   - ÎåÄÏÉÅ ÎèÖÏûê

3. **### Î∞©Î≤ïÎ°† (Methodology)**:
   - Îç∞Ïù¥ÌÑ∞ ÏàòÏßë Î∞©Î≤ï (ArXiv, Ï†ÑÎ¨∏ Î≥¥Í≥†ÏÑú, Îâ¥Ïä§)
   - Î∂ÑÏÑù Ï†ëÍ∑ºÎ≤ï (Ìä∏Î†åÎìú Î∂ÑÎ•ò, 5ÎÖÑ Ï†ÑÎßù)

4. **### Íµ¨Ï°∞ (Structure)**:
   - Í∞Å ÏÑπÏÖòÏùò Í∞ÑÎûµÌïú ÏÑ§Î™Ö

**Ï§ëÏöî**: Í∞Å ÌååÌä∏(Î∞∞Í≤Ω, Î™©Ï†Å, Î∞©Î≤ïÎ°†, Íµ¨Ï°∞) ÏïûÏóê `###` ÎßàÌÅ¨Îã§Ïö¥ Ìó§ÎçîÎ•º Î∞òÎìúÏãú ÏÇ¨Ïö©ÌïòÏÑ∏Ïöî.
Í∏∏Ïù¥: 500-700Îã®Ïñ¥
ÌÜ§: Ï†ÑÎ¨∏Ï†ÅÏù¥Í≥† Í∞ùÍ¥ÄÏ†Å

IntroductionÎßå ÏûëÏÑ±ÌïòÏó¨ Î∞òÌôòÌïòÏÑ∏Ïöî (ÎßàÌÅ¨Îã§Ïö¥ ÌòïÏãù, "## 1. Introduction" Ï†úÎ™© Ìè¨Ìï®)."""
        )
        self.intro_chain = intro_prompt | self.llm | str_parser
        
        # Conclusion Chain
        conclusion_prompt = ChatPromptTemplate.from_template(
            """ÎãπÏã†ÏùÄ AI/Î°úÎ≥¥Ìã±Ïä§ Ï†ÑÎ¨∏ Î≥¥Í≥†ÏÑú ÏûëÍ∞ÄÏûÖÎãàÎã§.

Îã§Ïùå Î∂ÑÏÑù Í≤∞Í≥ºÎ•º Î∞îÌÉïÏúºÎ°ú **6. Conclusion**ÏùÑ ÏûëÏÑ±ÌïòÏÑ∏Ïöî:

**Í∏∞Ïà† Ìä∏Î†åÎìú Î∂ÑÏÑù:**
{section_2}

**ÏãúÏû• ÎèôÌñ•:**
{section_3}

**5ÎÖÑ Í∏∞Ïà† Ï†ÑÎßù:**
{section_4}

**ÎπÑÏ¶àÎãàÏä§ ÏãúÏÇ¨Ï†ê:**
{section_5}

**ÌïµÏã¨ Ìä∏Î†åÎìú:**
{key_trends}

**Conclusion ÏûëÏÑ± ÏöîÍµ¨ÏÇ¨Ìï≠:**

1. **ÌïµÏã¨ Î∞úÍ≤¨ÏÇ¨Ìï≠ (Key Findings)**:
   - 3-5Í∞úÏùò ÌïµÏã¨ Î∞úÍ≤¨ÏÇ¨Ìï≠
   - Îç∞Ïù¥ÌÑ∞ Í∏∞Î∞òÏùò Íµ¨Ï≤¥Ï†ÅÏù∏ Í≤∞Î°†

2. **ÎØ∏Îûò Ï†ÑÎßù (Future Outlook)**:
   - 2025-2027: HOT_TRENDSÏùò Ï£ºÎ•òÌôî
   - 2028-2030: RISING_STARSÏùò Í≤åÏûÑÏ≤¥Ïù∏Ï†Ä
   - Í∏∞Ïà† Î∞úÏ†Ñ Î∞©Ìñ•

3. **Í∂åÍ≥†ÏÇ¨Ìï≠ (Recommendations)**:
   - Í∏∞ÏóÖ/Ìà¨ÏûêÏûêÎ•º ÏúÑÌïú Í∂åÍ≥†
   - Ïó∞Íµ¨Ïûê/Í∞úÎ∞úÏûêÎ•º ÏúÑÌïú Í∂åÍ≥†
   - Ï†ïÏ±ÖÏûÖÏïàÏûêÎ•º ÏúÑÌïú Í∂åÍ≥†

4. **Îß∫ÏùåÎßê (Closing Remarks)**:
   - Î≥¥Í≥†ÏÑúÏùò ÏùòÏùò
   - ÏßÄÏÜçÏ†ÅÏù∏ Î™®ÎãàÌÑ∞ÎßÅ ÌïÑÏöîÏÑ±

Í∏∏Ïù¥: 600-800Îã®Ïñ¥
ÌÜ§: ÌÜµÏ∞∞Î†• ÏûàÍ≥† Ïã§Ìñâ Í∞ÄÎä•Ìïú

ConclusionÎßå ÏûëÏÑ±ÌïòÏó¨ Î∞òÌôòÌïòÏÑ∏Ïöî (ÎßàÌÅ¨Îã§Ïö¥ ÌòïÏãù, "## 6. Conclusion" Ï†úÎ™© Ìè¨Ìï®)."""
        )
        self.conclusion_chain = conclusion_prompt | self.llm | str_parser
    
    async def execute(self, state: PipelineState) -> PipelineState:
        """
        Report Synthesis Ïã§Ìñâ
        
        Args:
            state: PipelineState (ContentAnalysisAgent Ï∂úÎ†• Ìè¨Ìï®)
        
        Returns:
            Updated PipelineState with synthesis results
        """
        print(f"\n{'='*60}")
        print(f"üé® Report Synthesis Agent")
        print(f"{'='*60}\n")
        
        # Get input from ContentAnalysisAgent
        sections = state.get("sections", {})
        trends = state.get("trends", [])
        citations = state.get("citations", [])
        topic = state.get("user_input", "AI-Robotics Trend")
        
        arxiv_data = state.get("arxiv_data", {})
        rag_results = state.get("rag_results", {})
        news_data = state.get("news_data", {})
        
        arxiv_count = arxiv_data.get("total_count", 0) if arxiv_data else 0
        rag_count = rag_results.get("total_results", 0) if rag_results else 0
        news_count = news_data.get("total_articles", 0) if news_data else 0
        
        # Prepare section texts
        section_2 = self._combine_subsections(sections, "section_2")
        section_3 = self._combine_subsections(sections, "section_3")
        section_4 = self._combine_subsections(sections, "section_4")
        section_5 = self._combine_subsections(sections, "section_5")
        
        # Format key trends
        key_trends = self._format_trends(trends)
        
        try:
            # Generate sections concurrently
            print("üìù Generating Summary, Introduction, Conclusion...\n")
            
            # Summary
            print("   üîπ Generating Executive Summary...")
            summary = await self.summary_chain.ainvoke({
                "section_2": section_2,
                "section_3": section_3,
                "section_4": section_4,
                "section_5": section_5,
                "key_trends": key_trends
            })
            print("   ‚úÖ Executive Summary generated\n")
            
            # Introduction
            print("   üîπ Generating Introduction...")
            section_1 = await self.intro_chain.ainvoke({
                "topic": topic,
                "arxiv_count": arxiv_count,
                "rag_count": rag_count,
                "news_count": news_count
            })
            print("   ‚úÖ Introduction generated\n")
            
            # Conclusion
            print("   üîπ Generating Conclusion...")
            section_6 = await self.conclusion_chain.ainvoke({
                "section_2": section_2,
                "section_3": section_3,
                "section_4": section_4,
                "section_5": section_5,
                "key_trends": key_trends
            })
            print("   ‚úÖ Conclusion generated\n")
            
            # Generate References
            print("   üîπ Generating References...")
            references = self._generate_references(citations)
            print(f"   ‚úÖ References generated ({len(citations)} citations)\n")
            
            # Generate Appendix
            print("   üîπ Generating Appendix...")
            appendix = self._generate_appendix(trends, arxiv_count, rag_count, news_count)
            print("   ‚úÖ Appendix generated\n")
            
            # Update state
            state["summary"] = summary
            state["section_1"] = section_1
            state["section_6"] = section_6
            state["references"] = references
            state["appendix"] = appendix
            
            print(f"‚úÖ Report Synthesis Complete!")
            print(f"\nüìä Summary:")
            print(f"   - Summary: {len(summary)} chars")
            print(f"   - Introduction: {len(section_1)} chars")
            print(f"   - Conclusion: {len(section_6)} chars")
            print(f"   - References: {len(citations)} citations")
            print(f"   - Appendix: {len(appendix)} chars\n")
            
            return state
        
        except Exception as e:
            print(f"‚ùå Error in ReportSynthesisAgent: {str(e)}")
            raise
    
    def _combine_subsections(self, sections: Dict[str, str], section_prefix: str) -> str:
        """
        ÏÑúÎ∏åÏÑπÏÖòÎì§ÏùÑ ÌïòÎÇòÎ°ú Í≤∞Ìï©
        
        Args:
            sections: All sections dict
            section_prefix: e.g., "section_2"
        
        Returns:
            Combined section text
        """
        combined = []
        for key, value in sorted(sections.items()):
            if key.startswith(section_prefix):
                combined.append(value)
        
        return "\n\n".join(combined) if combined else "N/A"
    
    def _format_trends(self, trends: List[Any]) -> str:
        """
        Ìä∏Î†åÎìúÎ•º Ìè¨Îß∑ÌåÖ
        
        Args:
            trends: List of TrendTier objects
        
        Returns:
            Formatted trends text
        """
        if not trends:
            return "No trends classified yet."
        
        hot_trends = [t for t in trends if hasattr(t, 'tier') and t.tier == "HOT_TRENDS"]
        rising_stars = [t for t in trends if hasattr(t, 'tier') and t.tier == "RISING_STARS"]
        
        result = []
        
        if hot_trends:
            result.append("**HOT_TRENDS (1-2ÎÖÑ Ï£ºÎ•òÌôî):**")
            for trend in hot_trends[:5]:
                tech = getattr(trend, 'technology', 'Unknown')
                papers = getattr(trend, 'paper_count', 0)
                result.append(f"- {tech} ({papers} papers)")
        
        if rising_stars:
            result.append("\n**RISING_STARS (3-5ÎÖÑ Í≤åÏûÑÏ≤¥Ïù∏Ï†Ä):**")
            for trend in rising_stars[:5]:
                tech = getattr(trend, 'technology', 'Unknown')
                papers = getattr(trend, 'paper_count', 0)
                result.append(f"- {tech} ({papers} papers)")
        
        return "\n".join(result)
    
    def _generate_references(self, citations: List[CitationEntry]) -> str:
        """
        Ïù∏Ïö© Î™©Î°ùÏùÑ Ìè¨Îß∑ÌåÖ
        
        Args:
            citations: List of CitationEntry objects
        
        Returns:
            Formatted references markdown
        """
        if not citations:
            return "## REFERENCE\n\nNo citations available."
        
        result = ["## REFERENCE\n"]
        
        # Group by source type
        arxiv_cites = [c for c in citations if c.source_type == "arxiv"]
        news_cites = [c for c in citations if c.source_type == "news"]
        report_cites = [c for c in citations if c.source_type == "report"]
        
        if arxiv_cites:
            result.append("### Academic Papers (arXiv)\n")
            for cite in arxiv_cites:
                result.append(f"[{cite.number}] {cite.to_reference_text()}")
        
        if report_cites:
            result.append("\n### Expert Reports\n")
            for cite in report_cites:
                result.append(f"[{cite.number}] {cite.to_reference_text()}")
        
        if news_cites:
            result.append("\n### News Articles\n")
            for cite in news_cites:
                result.append(f"[{cite.number}] {cite.to_reference_text()}")
        
        return "\n".join(result)
    
    def _generate_appendix(
        self,
        trends: List[Any],
        arxiv_count: int,
        rag_count: int,
        news_count: int
    ) -> str:
        """
        Î∂ÄÎ°ù ÏÉùÏÑ±
        
        Args:
            trends: Trend tiers
            arxiv_count: ArXiv paper count
            rag_count: RAG document count
            news_count: News article count
        
        Returns:
            Formatted appendix markdown
        """
        result = ["## APPENDIX\n"]
        
        # A. Data Collection Summary
        result.append("### A. Data Collection Summary\n")
        result.append(f"- **ArXiv Papers**: {arxiv_count} papers")
        result.append(f"- **Expert Reports**: {rag_count} documents")
        result.append(f"- **News Articles**: {news_count} articles")
        result.append(f"- **Total Data Sources**: {arxiv_count + rag_count + news_count}\n")
        
        # B. Trend Classification Details
        if trends:
            result.append("### B. Trend Classification Details\n")
            
            hot_trends = [t for t in trends if hasattr(t, 'tier') and t.tier == "HOT_TRENDS"]
            rising_stars = [t for t in trends if hasattr(t, 'tier') and t.tier == "RISING_STARS"]
            
            result.append(f"**HOT_TRENDS**: {len(hot_trends)} technologies")
            result.append(f"**RISING_STARS**: {len(rising_stars)} technologies\n")
        
        # C. Methodology Notes
        result.append("### C. Core Methodology\n")
        result.append("This report was generated using a multi-agent system with the following key methodologies:\n")
        
        result.append("1. **Human-in-the-Loop (HITL) for Planning & Writing:**")
        result.append("   - **Planning Phase:** The initial research plan generated by the AI is reviewed and refined by a human expert to ensure alignment and quality.")
        result.append("   - **Writing Phase:** The final draft is reviewed by a human who can request revisions or data recollection, creating an iterative refinement loop.\n")
        
        result.append("2. **ReAct-based Autonomous Data Collection:**")
        result.append("   - An autonomous agent based on the ReAct (Reasoning and Acting) framework dynamically collects data from various sources.")
        result.append("   - **Sources:** arXiv for academic papers, and real-time news crawling for market signals.\n")
        
        result.append("3. **Hybrid Retrieval-Augmented Generation (RAG):**")
        result.append("   - A sophisticated RAG system enhances the agent's knowledge by retrieving information from expert documents.")
        result.append("   - **Method:** It employs a hybrid search approach combining keyword-based search (BM25) and semantic search (Cosine Similarity), with a Maximal Marginal Relevance (MMR) reranker to ensure result diversity and relevance.\n")
        
        result.append("4. **Automated Analysis & Synthesis:**")
        result.append("   - **2-Tier Trend Classification:** Technologies are classified into 'HOT_TRENDS' (1-2 year horizon) and 'RISING_STARS' (3-5 year horizon).")
        result.append("   - **Automated Report Generation:** All sections, including summaries and conclusions, are synthesized by specialized agents, then assembled and translated into the final report.\n")
        
        return "\n".join(result)


